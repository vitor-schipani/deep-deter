# Deep DETER üå≥ü´∏ üî•

#### Using Satellite üõ∞Ô∏è remote sensing  and Deep Learning to automatically detect illegal deforestation in the Amazon rainforest.

#### Project created and submitted by Vitor Luiz Schipani as the final project for the [CS7643 - Deep Learning](https://omscs.gatech.edu/cs-7643-deep-learning) course from the Georgia Institute of Technology (Georgia Tech). This is part of the Master's in Computer Science degree program.

## What is this project about?
The Amazon Rainforest covers over 5 million square kilometers and represents half of Earth's remaining Rainforests. However rampant deforestation, man-made wildfires, illegal expansion of soy and cattle farms and mining activities are a significant cause for concern, see \cite{Oliveira2020Forest} for a review of these unsustainable practices. Keeping as much of the original tree coverage intact is important to keep it functioning as a forest (i.e.: regulating the climate, being the ancestral home of Indigenous tribes and hosting wildlife).

The repercussions of the degradation of the Amazon Rainforest can go beyond the forest given its complex interactions with the world climate. The loss of a significant tract of the forest can have irreversible negative consequences such as the acceleration of desertification, reduction in crop yields and perturbations in rainfall patterns in unexpected ways across distant regions.

## Why Deep Learning?
Deep Learning is an efficient way of intepreting satellite imagery without requiring Human labeling.

## Which sources of data are used to train the model?
Two sources of data are leveraged for training this model:
1. For the **labels (model targets)** we use data made available by the **PRODES** and the **DETER** program from INPE (See section below for more information about these programs).
2. For the **features (the actual satellite pictures)** Sentinel-2 data was used. Sentinel-2 data is made available by the Copernicus
Programme of the European Union. The data is accessed through Google's Earth Engine API through its Python Client.

## How can I run the project myself?
See the **SETUP** section at the bottom of this README for the necessary steps.


## Project Structure
```
‚îú‚îÄ‚îÄ LICENSE
‚îú‚îÄ‚îÄ Makefile                                <- Make sure you first configure and activate the Conda environment and are in the project root directory first.
‚îú‚îÄ‚îÄ README.md                               <- The top-level README.
‚îú‚îÄ‚îÄ data
‚îÇ   ‚îú‚îÄ‚îÄ external                            <- Data from PRODES and DETER programs.
‚îÇ   ‚îú‚îÄ‚îÄ raw                                 <- Original data pulled from Earth Engine API.
‚îÇ   ‚îú‚îÄ‚îÄ processed                           <- Processed data with all .tif bands joined together and Labels.
‚îÇ   ‚îú‚îÄ‚îÄ model_inputs                        <- These are the data_files split into train/test.
‚îÇ   ‚îú‚îÄ‚îÄ images                              <- .png files including model features (satellite images).
‚îÇ   ‚îî‚îÄ‚îÄ model_result                        <- Model results as .tif files.
‚îÇ
‚îú‚îÄ‚îÄ environment.yaml                        <- Used to install necessary packages. See setup section on how to use this file.
‚îÇ
‚îî‚îÄ‚îÄ deep_deter                              <- Source code for use in this project.
    ‚îÇ
    ‚îú‚îÄ‚îÄ data_extraction                     <- All scripts related to extracting data.
    ‚îÇ   ‚îú‚îÄ‚îÄ main.py                         <- USE THIS ONE. Do not run directly the other scripts.
    ‚îÇ   ‚îú‚îÄ‚îÄ custom_error.py
    ‚îÇ   ‚îú‚îÄ‚îÄ fetch_sentinel_img.py
    ‚îÇ   ‚îú‚îÄ‚îÄ mask_feature_bands.py
    ‚îÇ   ‚îú‚îÄ‚îÄ mask_label.py
    ‚îÇ   ‚îú‚îÄ‚îÄ mask_sentinel_img.py
    ‚îÇ   ‚îú‚îÄ‚îÄ plotting_utils.py
    ‚îÇ   ‚îú‚îÄ‚îÄ save_to_disk.py
    ‚îÇ   ‚îú‚îÄ‚îÄ train_test_split.py
    ‚îÇ   ‚îî‚îÄ‚îÄ utils.py
    ‚îÇ
    ‚îî‚îÄ‚îÄ deep_model                          <- Scripts to train the deep learning model.
        ‚îú‚îÄ‚îÄ train.py                        <- USE THIS ONE. Do not run directly the other scripts.
        ‚îú‚îÄ‚îÄ dataset.py
        ‚îú‚îÄ‚îÄ model.py
        ‚îî‚îÄ‚îÄ utils.py
```

## SETUP
### Setting up the environment
First activate Conda and install the environment:

> make install_env

or

> conda env create -f environment.yaml
